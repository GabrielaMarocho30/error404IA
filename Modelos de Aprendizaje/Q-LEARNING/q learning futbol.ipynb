{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3FCC0cyirN2jdjXF7Ud34"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Importamos las librerias necesarias**"],"metadata":{"id":"WZsxGfVH_1Z_"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"RkLN5PaT8r3W","executionInfo":{"status":"ok","timestamp":1729530470549,"user_tz":300,"elapsed":1102,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random"]},{"cell_type":"markdown","source":["#**Importamos el dataset**"],"metadata":{"id":"I4UuBBpsG386"}},{"cell_type":"code","source":["# Cargar los datos\n","df = pd.read_csv('equipos_futbol.csv')\n","\n","# Simplificación: Generar una columna que indique el resultado (0 = derrota, 1 = empate, 2 = victoria)\n","# En este caso, usaremos una métrica como \"%GanecomoLocal\" para determinar el resultado.\n","df['Resultado'] = df['%GanecomoLocal'].apply(lambda x: 2 if x > 50 else (1 if x == 50 else 0))"],"metadata":{"id":"DLC1eHRN8uKn","executionInfo":{"status":"ok","timestamp":1729530516381,"user_tz":300,"elapsed":554,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#**Definimos los campos de entrenamiento**"],"metadata":{"id":"PKj8-dytG_lV"}},{"cell_type":"code","source":["# Definir las características (X) y la etiqueta de salida (y)\n","features = ['Posesion%', 'AciertoPase%', 'Goles', 'Tiros pp', 'Tarjetas Amarillas', 'Tarjetas Rojas']\n","X = df[features]\n","y = df['Resultado']\n","\n","# Normalizar las características\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"jNXA4vZwCuYj","executionInfo":{"status":"ok","timestamp":1729530522675,"user_tz":300,"elapsed":2625,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#**Definimos la tabla Q**"],"metadata":{"id":"pHl4j7puHEtu"}},{"cell_type":"code","source":["# Inicializar la tabla Q\n","n_states = len(X_scaled)  # Número de estados (cada partido es un estado)\n","n_actions = 3  # 0: derrota, 1: empate, 2: victoria\n","Q_table = np.zeros((n_states, n_actions))\n","\n","# Parámetros de Q-learning\n","alpha = 0.1  # Tasa de aprendizaje\n","gamma = 0.9  # Factor de descuento\n","epsilon = 0.1  # Factor de exploración"],"metadata":{"id":"liMkaej2Cx7G","executionInfo":{"status":"ok","timestamp":1729530524993,"user_tz":300,"elapsed":648,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#**Definimos funciones de elección**"],"metadata":{"id":"RickJiMQHJQY"}},{"cell_type":"code","source":["# Función para elegir la acción (exploración-explotación)\n","def choose_action(state, epsilon):\n","    if random.uniform(0, 1) < epsilon:\n","        return random.randint(0, n_actions - 1)  # Acción aleatoria (explorar)\n","    else:\n","        return np.argmax(Q_table[state, :])  # Mejor acción (explotar)\n","\n","# Función para obtener la recompensa (predicción correcta o incorrecta)\n","def get_reward(predicted_action, true_result):\n","    return 1 if predicted_action == true_result else -1"],"metadata":{"id":"Pvpy9M6aCu9-","executionInfo":{"status":"ok","timestamp":1729530526966,"user_tz":300,"elapsed":2,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#**Entrenamos el modelo**"],"metadata":{"id":"mo2dIyWdHPQz"}},{"cell_type":"code","source":["# Entrenamiento del agente\n","n_episodes = 1000  # Número de episodios de entrenamiento\n","\n","for episode in range(n_episodes):\n","    state = random.randint(0, n_states - 1)  # Estado inicial aleatorio (partido)\n","\n","    for _ in range(100):  # Máximo 100 pasos por episodio\n","        # Elegir una acción (predicción)\n","        action = choose_action(state, epsilon)\n","\n","        # Obtener el verdadero resultado del partido (etiqueta real)\n","        true_result = y.iloc[state]\n","\n","        # Obtener la recompensa\n","        reward = get_reward(action, true_result)\n","\n","        # Determinar el siguiente estado (partido siguiente)\n","        next_state = (state + 1) % n_states\n","\n","        # Actualizar la tabla Q\n","        best_next_action = np.argmax(Q_table[next_state, :])\n","        Q_table[state, action] = Q_table[state, action] + alpha * (reward + gamma * Q_table[next_state, best_next_action] - Q_table[state, action])\n","\n","        # Cambiar al siguiente estado\n","        state = next_state"],"metadata":{"id":"gexhS5tZC4JM","executionInfo":{"status":"ok","timestamp":1729530531190,"user_tz":300,"elapsed":2230,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#**Medimos la precision**"],"metadata":{"id":"5_SRlCkJHR1p"}},{"cell_type":"code","source":["# Probar el agente después del entrenamiento\n","correct_predictions = 0\n","for state in range(n_states):\n","    action = np.argmax(Q_table[state, :])  # Predicción basada en la tabla Q\n","    true_result = y.iloc[state]\n","    if action == true_result:\n","        correct_predictions += 1\n","\n","accuracy = correct_predictions / n_states\n","print(f\"Precisión del agente con Q-learning: {accuracy * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnNz1u30DCw8","executionInfo":{"status":"ok","timestamp":1729530534580,"user_tz":300,"elapsed":655,"user":{"displayName":"EFRAM ABDEEL SAMUEL SILVA TRESIERRA","userId":"07883142797189098760"}},"outputId":"42f19510-e46d-4410-b002-c90ef8317183"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Precisión del agente con Q-learning: 100.00%\n"]}]}]}